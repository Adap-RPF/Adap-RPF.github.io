<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments</title>
  <link rel="icon" type="image/x-icon" href="">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered" style="max-width: 150%; width: 100%; padding-left: 0; padding-right: 0;">
            <h1 class="title is-1 publication-title" 
                style="width: 100%; word-wrap: break-word; font-size: 2.5rem; line-height: 1.3;">
              Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments
            </h1>
                
                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Arxiv PDF link  need revise-->
                      <span class="link-block">
                        <a href="http://arxiv.org/abs/2505.07446" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>

                    <!-- Video -->
                    <!-- <span class="link-block">
                      <a href="https://youtu.be/LLZT9cEa6K0" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span> -->

                <!-- Github link -->
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (TODO)</span>
                  </a>
                </span>

                <!-- Github link -->
                <!-- <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Real-World Deployment Code (ROS)</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image -->
<!-- <section class="hero teaser">
  <div class="hero-body">
    <div class="container">
      <img src="static/images/cover.png" alt="MY ALT TEXT" style="width: 100%; max-width: 1600px; height: auto;"/>
      <h2 class="subtitle has-text-centered">
        xxx
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser image -->

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/icra2026.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- ===== Teaser Figure (before Abstract) ===== -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <figure class="has-text-centered" style="margin-top:1rem;">
        <img src="static/images/figure1.png" alt="Adap-RPF teaser figure"
             style="max-width:100%;height:auto;border-radius:12px;box-shadow:0 10px 30px rgba(0,0,0,.08);" />
        <figcaption class="is-size-5" style="margin-top:0.75rem;color:#363636;line-height:1.6;">
          <em>Adap-RPF in a real-world dynamic crowded environment.</em>
          The robot proactively avoids dynamic occlusions (the pedestrian outlined
          in red) by adaptively sampling trajectory based on predicted human motion
          (colored arrows). Dashed outlines indicate agent positions at time T0,
          while solid outlines indicate their positions at time T1. The golden star marks the
          selected optimal following point, and golden circles indicate the candidate points.
        </figcaption>
      </figure>
    </div>
  </div>
</section>
<!-- ===== End Teaser Figure ===== -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>        <div class="content has-text-justified">
          <p>
            Robot person following (RPF) is a core capability in human-robot interaction, enabling robots to assist users in daily activities, collaborative work, and other service scenarios. However, achieving practical RPF remains challenging due to frequent occlusions, particularly in dynamic and crowded environments. Existing approaches often rely on fixed-point following or sparse candidate-point selection with oversimplified heuristics, which cannot adequately handle complex occlusions caused by moving obstacles such as pedestrians. To address these limitations, we propose an adaptive trajectory sampling method that generates dense candidate points within socially aware zones and evaluates them using a multi-objective cost function. Based on the optimal point, a person-following trajectory is estimated relative to the predicted motion of the target. We further design a prediction-aware model predictive path integral (MPPI) controller that simultaneously tracks this trajectory and proactively avoids collisions using predicted pedestrian motions. Extensive experiments show that our method outperforms state-of-the-art baselines in smoothness, safety, robustness, and human comfort, with its effectiveness further demonstrated on a mobile robot in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Review</h2>
        <div class="content has-text-justified">
          <p>
            We focus on two critical and quantifiable requirements that are frequently prioritized: <strong>safety</strong> and <strong>comfort</strong>:
          </p>
          <ul>
            <li>
              <strong>Safety:</strong>
              An objective requirement, ensuring that the robot avoids collisions while maintaining continuous observation of the target person.
            </li>
            <li>
              <strong>Comfort:</strong>
              In contrast, this is more subjective and is typically reflected in the robot's motion patterns and the relative distances between the robot, the target person, and surrounding pedestrians (i.e., proxemics). Higher-level aspects of comfort are beyond the scope of this review, such as following and approaching behaviors, group following, or explicit human-robot interaction.
            </li>
          </ul>
          <p>
            Based on these two requirements, we review <strong>RPF-related scenarios, evaluation metrics and planners</strong>. To enable systematic benchmarking, we introduce <strong>Follow-Bench</strong>, a unified benchmark for evaluating RPF planners under diverse conditions, including various <strong>target trajectory patterns, pedestrian-flow patterns, and environmental layouts</strong>. We re-implement six popular RPF planners, ensuring that both safety and comfort are systematically considered, including: <strong>MPC-based, MPC w/ Traj., MPC w/ DS., SFM-based, DWA-based and DWA w/ Traj.</strong>
          </p>
           
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- ===== Framework Design ===== -->
<!-- <section class="section">
  <div class="container" style="max-width:1400px;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Framework Design</h2>
        <div class="content has-text-justified">

          <figure class="has-text-centered" style="margin-top:1rem;">
            <img src="static/images/sampling.png" 
                 alt="Framework Design Diagram" 
                 style="width:100%;max-width:100%;height:auto;border-radius:12px;
                        box-shadow:0 10px 30px rgba(0,0,0,.1);" />
            <figcaption class="is-size-5" 
                        style="margin-top:0.75rem;color:#363636;text-align:center;line-height:1.6;">
              <strong>Target-centric Adaptive Following Trajectory Sampling.</strong>
              (a) <strong>Following Trajectory Sampling.</strong> Candidate following points are generated 
              using Sobol sampling within a target-centric semi-annular region defined by the target’s personal 
              and social zones. The candidates are evaluated using a multi-objective cost function that accounts 
              for target visibility, collision risk, social compliance, and smoothness. A following trajectory 
              is then constructed relative to the predicted target trajectory using an offset 
              (<em>d</em>, <em>θ</em>) based on the selected optimal point.
              (b) <strong>Proximity Cost.</strong> Minimum distance <em>d<sub>1</sub></em> to surrounding 
              pedestrians is computed from predicted trajectories and social zones; candidates intruding into 
              personal space (e.g., <strong>C<sub>t</sub><sup>3</sup></strong>, <strong>C<sub>t</sub><sup>1</sup></strong>) 
              are discarded, and <strong>C<sub>t</sub><sup>2</sup></strong> is selected.
              (c) <strong>Occlusion Cost.</strong> Occlusion is estimated via IoU between pedestrian and 
              target projections (<strong>P<sub>t+N</sub><sup>h</sup></strong> and 
              <strong>P<sub>t+N</sub><sup>Tar</sup></strong>) using predicted trajectories; 
              <strong>C<sub>t</sub><sup>1</sup></strong> is rejected due to partial occlusion (light gray), 
              whereas <strong>C<sub>t</sub><sup>2</sup></strong> remains visible.
              (d) <strong>Distance Cost.</strong> Penalizes deviation from the desired spacing to the target.
              (e) <strong>Travel Cost.</strong> Encourages minimal path effort from the robot’s current 
              position (green rectangle <strong>P<sub>t</sub><sup>R</sup></strong>).
              (f) <strong>Stickiness Cost.</strong> Promotes continuity by favoring points near the 
              previously selected following point.
            </figcaption>
          </figure>

        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- ===== End Framework Design ===== -->


<!-- ===== Framework Design ===== -->
<section class="section">
  <div class="container" style="max-width:1400px;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-2">Framework Design</h2>
        <div class="content has-text-justified">

          <!-- 图像 -->
          <figure class="has-text-centered" style="margin-top:1rem;">
            <img src="static/images/sampling.png" 
                 alt="Framework Design Diagram" 
                 style="width:100%;max-width:100%;height:auto;border-radius:12px;
                        box-shadow:0 10px 30px rgba(0,0,0,.1);" />
          </figure>
          <p class="is-size-5" 
            style="margin-top:0.75rem;color:#363636;text-align:justify;line-height:1.7;">
            <span style="font-weight:600;color:#000;">Target-centric Adaptive Following Trajectory Sampling.</span> 
            <span style="font-weight:600;color:#000;">(a) Following Trajectory Sampling.</span> Candidate following points are generated using Sobol sampling within a target-centric semi-annular region defined by the target’s personal and social zones. The candidates are evaluated using a multi-objective cost function that accounts for target visibility, collision risk, social compliance, and smoothness. A following trajectory is then constructed relative to the predicted target trajectory using an offset (<em>d</em>, <em>θ</em>) based on the selected optimal point. 
            <span style="font-weight:600;color:#000;">(b) Proximity Cost.</span> Minimum distance <em>d<sub>1</sub></em> to surrounding pedestrians is computed from predicted trajectories and social zones; candidates intruding into personal space (e.g., <em>C<sub>t</sub><sup>3</sup></em>, <em>C<sub>t</sub><sup>1</sup></em>) are discarded, and <em>C<sub>t</sub><sup>2</sup></em> is selected. 
            <span style="font-weight:600;color:#000;">(c) Occlusion Cost.</span> Occlusion is estimated via IoU between pedestrian and target projections (<em>P<sub>t+N</sub><sup>h</sup></em> and <em>P<sub>t+N</sub><sup>Tar</sup></em>) using predicted trajectories; <em>C<sub>t</sub><sup>1</sup></em> is rejected due to partial occlusion (light gray), whereas <em>C<sub>t</sub><sup>2</sup></em> remains visible. 
            <span style="font-weight:600;color:#000;">(d) Distance Cost.</span> Penalizes deviation from the desired spacing to the target. 
            <span style="font-weight:600;color:#000;">(e) Travel Cost.</span> Encourages minimal path effort from the robot’s current position (green rectangle <em>P<sub>t</sub><sup>R</sup></em>). 
            <span style="font-weight:600;color:#000;">(f) Stickiness Cost.</span> Promotes continuity by favoring points near the previously selected following point.
          </p>

        </div>
      </div>
    </div>
  </div>
</section>
<!-- ===== End Framework Design ===== -->

<!-- ===== Evaluation ===== -->
<section class="section hero is-light">
  <div class="container" style="max-width:1400px;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-2">Evaluation</h2>
        <h3 class="title is-4 has-text-centered">Baseline Comparision</h3>
        <div class="content has-text-justified">

          <!-- 图像 -->
          <figure class="has-text-centered" style="margin-top:1rem;">
            <img src="static/images2/baseline2.png" 
                 alt="Framework Design Diagram" 
                 style="width:100%;max-width:100%;height:auto;border-radius:12px;
                        box-shadow:0 10px 30px rgba(0,0,0,.1);" />
          </figure>

          <p class="is-size-5" 
             style="margin-top:0.75rem;color:#363636;text-align:justify;line-height:1.7;">

            To evaluate the performance of target visibility and following performance on the benchmark, 
            we compare our <span style="font-weight:600;color:#000;">Adap-RPF</span> method with several baselines categorized as follows: 
            <span style="font-weight:600;color:#000;">(1) Multiple Predefined Following Points.</span> 
            <strong>Vu's Method</strong> adopts a similar 
            frame-sample-evaluate-plan approach to ours but leverages current scene observations for following 
            points selection and local planning. 
            <span style="font-weight:600;color:#000;">(2) Optimization-based.</span> 
            <strong>Wang's Method</strong> is the first 
            to propose maintaining target visibility in RPF by formulating an optimization function within the 
            NMPC framework, incorporating multiple constraints. 
            <span style="font-weight:600;color:#000;">(3) Fixed Following Point.</span> 
            <strong>RDA Planner Trajectory Following (RDA-Traj)</strong> achieves SOTA performance in the public 
            benchmark.
            <span style="font-weight:600;color:#000;">Our method outperforms others inmost case.</span> 
          </p>

          <h3 class="title is-4 has-text-centered">Ablation Study</h3>
          <div class="content has-text-justified">
  
            <!-- 图像 -->
            <figure class="has-text-centered" style="margin-top:1rem;">
              <img src="static/images2/ablation.png" 
                   alt="Framework Design Diagram" 
                   style="width:100%;max-width:100%;height:auto;border-radius:12px;
                          box-shadow:0 10px 30px rgba(0,0,0,.1);" />
            </figure>
  
            <p class="is-size-5" 
               style="margin-top:0.75rem;color:#363636;text-align:justify;line-height:1.7;">
               To assess the contributions of adaptive trajectory sampling and human trajectory prediction for it and MPPI, we conduct ablation studies using TVR and TSR as evaluation metrics. 
               <span style="font-weight:600;color:#000;">The best performance is achieved when these components are effectively combined.</span>
            </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- ===== End Evaluations ===== -->

<!-- Image carousel -->
<!-- <section class="section">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Benchmark Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/average.png" alt="MY ALT TEXT"/>
      </div>
      <div class="item">
        <img src="static/images/humanNumsAndOcc.png" alt="MY ALT TEXT"/>
      </div>
      <div class="item">
        <img src="static/images/dists.png" alt="MY ALT TEXT"/>
     </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->

<!-- Video carousel -->
<section class="hero is-light">
  <!-- <div class="hero-body">
    <div class="container has-text-centered">
      <h2 class="title is-3">Real-world Experiments</h2>

      <!-- 三栏轮播，每栏两段视频 -->
      <div id="results-carousel" class="carousel results-carousel" data-infinite="true">
        <!-- 第一栏 -->
        <div class="item">
          <div class="columns is-centered">
            <div class="column is-half">
              <video poster="" autoplay controls muted loop width="100%">
                <source src="static/videos/rda-naive-combined-720p.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <video poster="" autoplay controls muted loop width="100%">
                <source src="static/videos/rda-traj-naive-combined-720p.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <p class="subtitle is-6">MPC w/ Traj. provides smoother motion than MPC-based.</p>
        </div>

        <!-- 第二栏 -->
        <div class="item">
          <div class="columns is-centered">
            <div class="column is-half">
              <video poster="" autoplay controls muted loop width="100%">
                <source src="static/videos/rda-static-combined-720p.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <video poster="" autoplay controls muted loop width="100%">
                <source src="static/videos/rda-traj-static-combined-720p.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <p class="subtitle is-6">MPC w/ Traj. can generate wider-arc motions to avoid collision or stuck, but suffers from temporary target loss under limited camera FoV and may reduce user comfort.</p>
        </div>

        <!-- 第三栏 -->
        <div class="item">
          <div class="columns is-centered">
            <div class="column is-half">
              <video poster="" autoplay controls muted loop width="100%">
                <source src="static/videos/rda-dynamic-combined-720p.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <video poster="" autoplay controls muted loop width="100%">
                <source src="static/videos/rda-traj-dynamic-combined-720p.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          <p class="subtitle is-6">Both MPC w/ Traj. and MPC are reactive rather than proactive, as they do not explicitly model pedestrian motion.</p>
        </div>

      </div>
    </div>
  </div> -->
</section>
<!-- End video carousel -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Simulation and Real-World Experiments</h2>
        <div class="content has-text-centered" style="margin-top:1rem;">
          <video 
            autoplay 
            controls 
            muted 
            loop 
            style="width:100%;max-height:600px;border-radius:12px;box-shadow:0 8px 24px rgba(0,0,0,0.1);">
            <source src="static/videos/icra2026.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p style="margin-top:0.75rem;font-size:0.95rem;color:#363636;">
            Demonstrations of simulation and real-world person-following experiments.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Challenges and Future Directions</h2>
        <div class="content has-text-justified">
          <ul>
            <li>
              <strong>Balancing Trade-offs between Safety and Comfort:</strong>
              Most RPF planners struggle with the trade-off between keeping a socially comfortable distance to the target and avoiding collisions, especially in crowded or cluttered environments. Fixed point/trajectory tracking often leads to occlusions and safety risks, while optimization-based planners face computational challenges in dynamic settings. Promising directions include (i) adaptive trajectory prediction that integrates human motion forecasts and visibility constraints, (ii) convexified or sampling-based MPC to reduce real-time complexity, and (iii) hierarchical planning that separates high-level candidate generation from low-level collision-free execution.
            </li>
            <li>
              <strong>Improving Spatial-temporal Obstacle Representation, Prediction and Planning:</strong>
              Current polygon-based clustering works for discrete clutter but struggles with continuous structures (e.g., walls, doorways) and may merge targets with nearby obstacles. Future work should develop more robust obstacle representations and adaptive safe distances for different spatial contexts. Incorporating not only target trajectories but also predictions of surrounding pedestrians—using advanced models like Social-GAN—can enable smoother, socially aware planning that balances visibility, safety, and proxemics.
            </li>
            <li>
              <strong>Discovering and Utilizing Environmental Patterns:</strong>
              Beyond short-term trajectory prediction, RPF can benefit from recognizing long-term crowd and environmental patterns. For example, following pedestrian flow at crosswalks or detouring around dense formations allows safer, more comfortable re-approach to the target. A promising direction is to integrate high-level pattern recognition with low-level planning to balance visibility, safety, and comfort in complex environments.
            </li>
            <li>
              <strong>Towards More Expressive Intermediate Representations:</strong>
              Point- or trajectory-based references often fail under occlusions, while cost maps and potential fields lack distance encoding and are costly to update. ESDFs provide smooth, distance-aware planning but remain computationally heavy in dynamic settings. Future directions include designing intermediate representations that jointly encode visibility, safety, and social constraints—potentially using learning-based methods for compact and adaptive modeling.
            </li>

          </ul>
           
        </div>
      </div>
    </div>
  </div>
</section> -->


<!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
